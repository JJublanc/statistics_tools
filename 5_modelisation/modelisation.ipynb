{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> <h1> Modélisation linéaire </h1> </center>\n",
    "\n",
    "<img src=\"../images/example.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le problème\n",
    "\n",
    "Les modèles linéaires sont intéressants en raison de leur interprétabilité. Ils donnent une approximation de phénomènes que l'on tente de comprendre.\n",
    "\n",
    "Lorsque l'on cherche à comprendre des phénomènes et déterminer des mécanismes explicatifs d'une variable de sortie, il peut être utile de réaliser une modélisation, notamment linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque individu i (un individu correspond à une ligne) d'une base de données on a des informations $x^i_1, x^i_2,..., x^i_n$ et une valeur réelle $y^i$ que l'on cherche à approximer. \n",
    "\n",
    "On cherche un modèle permettant d'approximer une variable (output) $y^i$, grâce à les variables explicatives (features/input) $x^i_1, x^i_2,..., x^i_n$ par l'équation suivante :\n",
    "$$\\hat{y}^i = \\alpha_1x^i_1 + \\alpha_2x^i_2 + ... + \\alpha_nx^i_n$$\n",
    "\n",
    "Avec : \n",
    "- i : un individu i d'une base de données\n",
    "- $\\hat{y}^i$ l'approximation de $\\hat{y}$\n",
    "- $\\alpha_1, \\alpha_2,..., \\alpha_n$ des coefficients réels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemples d'application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'on veut étudier l'effet d'une variable sur une autre il peut être intéressant d'avoir un modèle général d'explication de l'output pour estimer quelle influence va avoir la variable explicative d'intérêt tout en prenant en compte les autres facteurs explicatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "%run -i ../utils/credentials.py\n",
    "%run -i ../utils/imports.py\n",
    "%run -i ../utils/plots.py\n",
    "%run -i ../utils/stats.py\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/PUBG_train_sample.csv\"\n",
    "data_PUBG = pd.read_csv(data_path)\n",
    "data_PUBG = data_PUBG.sample(frac=0.01, replace=False, random_state=1234)\n",
    "data_PUBG_not_zero = data_PUBG[(data_PUBG[\"winPoints\"]!=0)&(data_PUBG[\"killPoints\"]!=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Les moindres carrés ordinaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les moindres carrés on tente de réaliser la meilleure approximation en choisissant des coefficient $\\hat{\\alpha_1}, \\hat{\\alpha_2},..., \\hat{\\alpha_n}$ qui vont minismiser l'erreur quadratique moyenne : \n",
    "$$\\frac{1}{n}\\sum_i(y^i-\\hat{y}^i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_PUBG[\"winPoints\"], data_PUBG[\"killPoints\"])\n",
    "plt.xlabel(\"x\", fontsize = 20)\n",
    "plt.ylabel(\"y\", fontsize = 20)\n",
    "plt.plot((1400,1700),(900,1900), c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solution des moindres carré existe et elle est analytique. Sous les hypothèses de Gauss-Markov elle a également la propriété d'être sans biais. Cela signifie que notre estimateur de $\\hat{\\alpha}$ vaut bien $\\alpha$ en moyenne.\n",
    "Ces conditions sont les suivantes : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothèses de Gauss-Markov.\n",
    "- Non colinéarité des variables explicatives : les variables explicatives ne sont pas des combinaisons linéaires des autres\n",
    "- Indépendance des erreurs : la valeur d'une erreur de dépend pas de celle d'une autre (ce qui est souvent faut pour les séries temporelles\n",
    "- Exogénéité : les variables sont indépendantes du terme d'erreur\n",
    "- Homoscédasticité : la variance des termes d'erreur est constante \n",
    "- Normalité des termes d'erreur : la distribution des termes d'erreur suit une loi normale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Intérprétation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Les coefficient__\n",
    "Chaque coefficient $\\alpha_i$ donne l'effet de la variable $x_i$ sur l'output. Si $x_1$ augmente de 1 alors la variable $y$ augmente de $\\alpha_i$.\n",
    "\n",
    "__La qualité du modèle__\n",
    "Pour savoir si un modèle linéaire est bon, plusieurs points peuvent être vérifiés :\n",
    "- les hypothèses sont-elles respectées ?\n",
    "- l'ajustement est-il correct ?\n",
    "\n",
    "Pour répondre à la deuxième question on peut calculer la part de la variance (en d'autres termes un indicateur de la variation) de y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_PUBG[\"winPoints\"]\n",
    "y = data_PUBG[\"killPoints\"]\n",
    "slope, intercept, r_value, p_value, std_err = scs.linregress(x, y)\n",
    "\n",
    "print(intercept)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "x = data_PUBG[\"winPoints\"]\n",
    "x = sm.add_constant(x)\n",
    "y = data_PUBG[\"killPoints\"]\n",
    "\n",
    "MCO_model = sm.GLM(y, x)\n",
    "MCO_model = MCO_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MCO_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCO_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCO_results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_PUBG[\"winPoints\"], data_PUBG[\"killPoints\"])\n",
    "\n",
    "# With all the data\n",
    "x = data_PUBG[\"winPoints\"]\n",
    "x = sm.add_constant(x)\n",
    "y = data_PUBG[\"killPoints\"]\n",
    "MCO_model = sm.GLM(y, x)\n",
    "MCO_results = MCO_model.fit()\n",
    "\n",
    "# With only non zero value\n",
    "x_not_zero = data_PUBG_not_zero[\"winPoints\"]\n",
    "x_not_zero = sm.add_constant(x_not_zero)\n",
    "y_not_zero = data_PUBG_not_zero[\"killPoints\"]\n",
    "MCO_model_not_zero = sm.GLM(y_not_zero, x_not_zero)\n",
    "MCO_results_not_zero = MCO_model_not_zero.fit()\n",
    "\n",
    "\n",
    "x_plot = np.linspace(0,1800)\n",
    "y_plot = MCO_results.params.const + MCO_results.params.winPoints*x_plot\n",
    "plt.plot(x_plot, y_plot, c = \"r\")\n",
    "\n",
    "x_plot_not_zero = np.linspace(0,1800)\n",
    "y_plot_not_zero = MCO_results_not_zero.params.const + MCO_results_not_zero.params.winPoints*x_plot\n",
    "plt.plot(x_plot_not_zero, y_plot_not_zero, c = \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_PUBG) - len(data_PUBG_not_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_PUBG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MCO_results_not_zero.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only non zero value\n",
    "x_not_zero = data_PUBG_not_zero[\"winPoints\"]\n",
    "x_not_zero = sm.add_constant(x_not_zero)\n",
    "y_not_zero = data_PUBG_not_zero[\"killPoints\"]\n",
    "MCO_model_not_zero = sm.GLM(y_not_zero, x_not_zero)\n",
    "MCO_results_not_zero = MCO_model_not_zero.fit()\n",
    "\n",
    "# With only non zero value\n",
    "x_not_zero_two_X = data_PUBG_not_zero[[\"winPoints\",\"winPoints\"]]\n",
    "x_not_zero_two_X = sm.add_constant(x_not_zero_two_X)\n",
    "MCO_model_not_zero_two_X = sm.GLM(y_not_zero, x_not_zero_two_X)\n",
    "MCO_results_not_zero_two_X = MCO_model_not_zero_two_X.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCO_results_not_zero_two_X.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " MCO_results_not_zero.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Qualité des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Le coefficient de détermination $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le $R^2$ est une première mesure de qualité du modèle qui donne une bonne idée de la qualité de la régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du $R^2$ : \n",
    "$$R^2 = \\frac{SSR}{SST}$$ \n",
    "- $SSR$ (regression sum of squares) $= \\sum_i(\\hat{y_i} - \\bar{y})^2$\n",
    "- $SST$ (total sum of squares) $= \\sum_i(y_i - \\bar{y})^2$\n",
    "\n",
    "Intuitivement le coefficient de détermination donne le rapport de la variance expliquée par le modèle ($\\frac{SSR}{n}$, variation de $\\hat{y}$) sur la variance totale ($\\frac{SST}{n}$, variation de $y$), c'est-à-dire la part de variance expliquée par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_square(y,y_hat):\n",
    "    SSR = np.sum((y_hat - np.mean(y_hat))**2)\n",
    "    SST = np.sum((y - np.mean(y_hat))**2)\n",
    "    return SSR/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, MCO_results.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_R_square(y, MCO_results.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_R_square(y_not_zero, MCO_results_not_zero.predict(x_not_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Le coefficient de détermination ajusté $\\bar{R}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\bar{R}^2= 1 - (1-R^2)\\times \\big(\\frac{n-1}{n-p-1}\\big)$$\n",
    "\n",
    "Avec :\n",
    "- $n$ : la taille de l'échantillon ($i \\in [1,...,n]$)\n",
    "- $p$ : le nombre de variables explicatives (hors cnostante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_R_square(y,y_hat, n, p):\n",
    "    r2 = compute_R_square(y,y_hat)\n",
    "    adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    return adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_R_square(y,MCO_results.predict(x), 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Take away</h1> </center>\n",
    "\n",
    "<img src=\"../images/coffee.png\" width=\"200\">\n",
    "\n",
    "\n",
    "__Expresso__ : \n",
    "\n",
    "* point 1\n",
    "* point 2\n",
    "\n",
    "__Sugar Story__ :\n",
    "\n",
    "* point 1\n",
    "* point 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get more on my github <img src=\"../images/github.png\" width=\"100\">\n",
    "https://github.com/JJublanc/statistics_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
