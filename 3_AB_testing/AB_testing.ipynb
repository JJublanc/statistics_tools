{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> <h1>Data description - exercices </h1> </center>\n",
    "\n",
    "<img src=\"../images/ab_testing.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "_TODO :\n",
    "    schema echantillonnage\n",
    "    ajout de la variable N dans le notebook exercices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pourquoi faire un A/B testing ?\n",
    "\n",
    "L'A/B testing permet de tester une différence de résultat en fonction d'un paramètre à deux modalités. Cette technique est notamment utile pour estimer si un nouveau produit ou une nouvelle feature à un impact positif sur le résultat attendu (taux de clics, de conversions, etc.) en comparant 2 groupes d’utilisateurs que l’on expose à des features/produits différent.e.s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques cas d'usage classics\n",
    "\n",
    "L'AB testing permer de valider la valeur ajoutée : \n",
    "* d’un nouvel algorithme de recommandation\n",
    "* d’un changement de backend\n",
    "* d’une modification de wording sur un site internet \n",
    "* d’un changement de disposition des éléments ou des couleurs d'une page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Des cas peu propices et des solutions alternatives\n",
    "\n",
    "Lorsque l'effet d'une modification est complexe ou à long terme, l'A/B testing est moins facile à mettre en place. Par exemple lors d'un changement de logo, les clients peuvent mettre du temps à s'habituer au changement. Dans ce cas l'A/B testing ne montrera pas forcémment les effet bénéfiques à long terme.\n",
    "\n",
    "Il existe des alternatives à l'A/B testing dans ces cas : \n",
    "* l'analyse des logs\n",
    "* la mise en place de focus groups et/ou d'enquêtes pour obtenir des réponses à des questions plus complexes\n",
    "* une évaluation humaine par des experts métier\n",
    "\n",
    "Dans certains cas également l'A/B testing est trop coûteux pour être mis en place. Dans le domaine médical, par exemple, il peut être très coûteux (financièrememt mais surtout moralement et humainement) d'appliquer le moins bon traitement à tout un groupe (A ou B). \n",
    "\n",
    "Ce problème est complexe car on ne connaît pas le meilleur traitement à l'avance, mais il est parfois possible de réaliser un A/B testing en formulant le use-case comme un problème de _multi-armed bandit_ et de le résoudre avec des techniques de reinforcement learning simple mais efficace pour minimiser le __regret__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"../images/warning.png\" width=\"200\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> \n",
    "    <span; style=\"margin-top:200px ; color:red;font-size:20px\">\n",
    "    Comparer juste des moyennes ne permet pas de conclure ! Même si le résultat semble évident.\n",
    "    </span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "%run -i ../utils/credentials.py\n",
    "%run -i ../utils/imports.py\n",
    "%run -i ../utils/plots.py\n",
    "%run -i ../utils/stats.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rappel\n",
    "\n",
    "Une variable aléatoire représente le résultat d'une expérience qui n'est pas entièrement déterminée à l'avance. \n",
    "\n",
    "Cette variable est souvent représentée par une loi déterminant la manière dont vont se répartir les résultats d'expériences identiques répétées un grand nombre de fois.\n",
    "\n",
    "Considérons le cas suivant : \n",
    "* le phénomène : l'erreur lors d'une mesure\n",
    "* le nombre d'expériences : 100 000\n",
    "\n",
    "La loi du phénomène peut dans une première approche être représentée par les effectifs pour chaque interval de valeur. Le graphique suivant montre trois cas différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# nombre de tirages\n",
    "nb_sample = 100000\n",
    "\n",
    "# écarts-types pour les tirages\n",
    "std1 = 5\n",
    "std2 = 3\n",
    "moy = 4\n",
    "\n",
    "# tirages\n",
    "x1 = np.random.normal(0,std1,nb_sample)\n",
    "x2 = np.random.normal(0,std2,nb_sample)\n",
    "x3 = np.random.normal(moy,std2,nb_sample)\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title=\"valeurs\"), \n",
    "                   yaxis=dict(title=\"effectifs\"),\n",
    "                   width=800,height=600)\n",
    "\n",
    "data = [go.Histogram(x=x1, name='écart-type = {}'.format(std1)), \n",
    "        go.Histogram(x=x2, name='écart-type = {}'.format(std2)),\n",
    "        go.Histogram(x=x3, name='moyenne = {}'.format(moy))]\n",
    "\n",
    "fig = go.Figure(data, layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En théorie on caractérise une loi grâce à sa fonction de densité. \n",
    "\n",
    "Pour une loi normale deux paramètres suffisent pour calculer la fonction de densité : sa moyenne ($\\mu$) et son écart-type ($\\sigma$). Cette loi est notée $\\mathcal{N}(\\mu,\\sigma)$.\n",
    "\n",
    "ATTENTION : certains auteurs utilisent la moyenne et la variance ($\\sigma^2$) pour décrire la même chose : $\\mathcal{N}(\\mu,\\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "loi = scs.norm(0,3)\n",
    "\n",
    "x1 = np.linspace(-10, 10, 1000)\n",
    "y1 = loi.pdf(x1)\n",
    "\n",
    "data = [go.Scatter(x=x1,y=y1)]\n",
    "layout = go.Layout(width=800,height=500)\n",
    "\n",
    "fig = go.Figure(data,layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Graphiquement la fonction de densité de la loi est représenté par une courbe ayant l'allure de celle ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilité d'avoir une valeur entre a et b est égale à l'air sous la courbe entre ces deux valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loi = scs.norm(0,1)\n",
    "\n",
    "x1 = np.linspace(-4, 4, 1000)\n",
    "y1 = loi.pdf(x1)\n",
    "\n",
    "x2 = np.linspace(-1.96, 1.96, 1000)\n",
    "y2 = loi.pdf(x2)\n",
    "\n",
    "trace1 = go.Scatter(x=x1,y=y1, name=\"densité\")\n",
    "trace2 = go.Scatter(x=x2,y=y2,fill='tozeroy',mode= 'none',name=\"proba\")\n",
    "\n",
    "data = [trace1,trace2]\n",
    "layout = go.Layout(width=800,height=500)\n",
    "\n",
    "fig = go.Figure(data,layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le principe du test\n",
    "On constitue un groupe A (de taille $N_A$) à qui on applique un paramètre et un groupe B (de taille $N_B$) à qui on applique l'autre paramètre.\n",
    "\n",
    "Warning : il faut choisir les individus au hasard au sein de chaque groupe sinon on ne teste pas les paramètres mais les caractéristiques de sélection des groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plus précisément\n",
    "\n",
    "On cherche à répondre à la question suivante : les moyennes des deux séries $(x^A_1,...,x^A_{N_A})$ et $(x^B_1,...,x^B_{N_B})$ sont elles égales ou différentes ?\n",
    "\n",
    "$$\\bar{x}^A = \\bar{x}^B \\space ?$$\n",
    "\n",
    "\n",
    "**Les hypothèses du test**\n",
    "- $H_0$ : $$\\bar{x}^A = \\bar{x}^B \\space$$\n",
    "\n",
    "\n",
    "- $H_1$ : $$\\bar{x}^A > \\bar{x}^B \\space$$\n",
    "\n",
    "Pour le moment on fait l'hypothèse que N est relativement grand ($N_A$>30 et $N_B$>30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Idée centrale du test : sous l'hypothèse nulle l'écart entre les deux moyennes suit une loi normale centrée en 0 et de variance connue.__\n",
    "\n",
    "**Si H0 est vraie**\n",
    "\n",
    "La différence entre les deux moyennes normalisée (avec les écarts-types) devrait être proche de 0. \n",
    "\n",
    "Plus précisémment, le théorème central limite nous permet de dire que la valeur cette différence peut être approximée par une loi normale centrée en 0. \n",
    "\n",
    "Cela signifie que si l'on calcule la moyenne sur deux échantillons (ceux correspondant à nos groupes A et B) et que l'on répète cette opération plusieurs fois, la différence entre les deux moyennes sera rarement très éloignée de 0. \n",
    "\n",
    "Formellement cela s'écrit : $$\\bar{X}^A - \\bar{X}^B\\rightarrow \\mathcal{N}\\Big(0,\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}\\Big)$$\n",
    "\n",
    "Avec : $$ S_J^2 = \\frac{1}{(N_J-1)}\\sum_i (x_i - \\bar{x_i})^2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Risque de première espèce : rejeter l'hypothèse nulle à tort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dans un cas concret on ne peut pas répéter plusieur fois l'opération de calcul de moyenne sur plusieurs couples d'échantillons A et B. On a une seule valeur qui est le résultat de notre test et que l'on appelle $t_{AB}$.\n",
    "\n",
    "Pour décider si on accepte l'hypothèse nulle on va fixer une valeur et si $t_{AB}$ est supérieur à cette valeur on va rejeter l'hypothèse d'égalité des moyennes.\n",
    "\n",
    "Pour cela on fixe l'intervalle de valeurs pour $t_{AB}$ dans lequel on accèpte notre hypothèse. Par exemple on accèpte notre hypothèse nulle si notre valeur $t_{AB}$ est comprise dans la zone où se situent 95% des valeurs théoriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loi = scs.norm(0,1)\n",
    "p = 0.95\n",
    "plot = plot_ppf(p=p,loi=loi, threshold = loi.ppf(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Risque de deuxième espèce : accépter l'hypothèse nulle à tort\n",
    "\n",
    "Le risque de deuxième espèce correspond au risque d'accépter l'hypothèse nulle dans le cas où l'écart réel entre les moyennes est à un niveau donné non nul.\n",
    "\n",
    "On parle de __puissance du test__ pour désigner la valeur complémentaire de ce risque. Par exemple lorsque le risque de second espèce est de 20%, la puissance du test est de 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lorsque l'on considère que l'écart réel entre les deux moyennes est très faible, on fait face à un risque de seconde espèce élevé. Par exemple si l'écart entre les deux moyennes est de 0.5 avec un écart-type estimé de 1, le risque de deuxième espèces est de 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loi1 = scs.norm(0,1)\n",
    "loi2 = scs.norm(0.5,1)\n",
    "t = loi1.ppf(0.95)\n",
    "plot_cdf_2_lois(loi1, loi2, threshold=False)(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plus l'écart entre les deux moyennes est élevé, plus le risque de seconde espèce est faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loi1 = scs.norm(0,1)\n",
    "loi2 = scs.norm(3,1)\n",
    "t = loi1.ppf(0.95)\n",
    "plot_cdf_2_lois(loi1, loi2)(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "De la même manière si les variances empiriques sont faibles (les mesures sont plus précises), le risque de seconde espèce est réduit. La séparation est \"plus nette\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loi1 = scs.norm(0,0.2)\n",
    "loi2 = scs.norm(0.5,0.2)\n",
    "t = loi1.ppf(0.95)\n",
    "plot_cdf_2_lois(loi1, loi2)(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En pratique comment ça se passe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A/ On commence par estimer la taille de l'échantillon nécessaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En pratique on calcule la taille de l'échantillon qui a \"_de bonnes chances_\" de nous permettre de détecter l'effet minimal qui nous intéresse avec des niveaux de risque réduits. Pour cela il faut faire des hypothèses sur la variance des résultats $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Les propriétés du test permettent de calculer la taille de l'échantillon permettant de respecter les niveaux de risque souhaités.\n",
    "\n",
    "$$N_A^{min} = N_B^{min} = \\frac{2\\times\\sigma^2\\times(Z_{\\alpha} + Z_{\\beta})^2}{(mde)^2} $$\n",
    "\n",
    "Avec :\n",
    "* $Z_\\alpha$ : la valeur au delà de laquelle on rejette $H_0$ avec un risque de 1er espèce $\\alpha$\n",
    "* $Z_\\beta$ : la valeur (modulo le $mde$) en deça de laquelle on accepte $H_0$ avec un risque de 2ème espèce $\\beta$\n",
    "* $\\sigma^2$ : la variance hypothétique des résultats\n",
    "* $mde$ : l'effet minimum détectable souhaité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def size_sample_AB_test(risk1, risk2, var, mde, bilateral = False):\n",
    "    \n",
    "    if bilateral :\n",
    "        Z_alpha = scs.norm(0,1).ppf(1 - risk1/2)\n",
    "    else :    \n",
    "        Z_alpha = scs.norm(0,1).ppf(1 - risk1)\n",
    "    \n",
    "    Z_beta = scs.norm(0,1).ppf(1 - risk2)\n",
    "\n",
    "    min_N = (2*(var)*(Z_beta + Z_alpha)**2/ mde**2)\n",
    "    \n",
    "    return min_N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Par exemple pour tester une différence de taux de clic, avec : \n",
    "* un risque de première espèce de 5%\n",
    "* un risque de deuxième espèce de 20%\n",
    "* un taux de clics de base de 5%\n",
    "* une différence détectable minimale de 1.5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "risk1 = 0.05\n",
    "risk2 = 0.2\n",
    "p = 0.5\n",
    "mde = 0.05\n",
    "pooled_prob = (2*p + mde) / 2\n",
    "var = pooled_prob*(1-pooled_prob) # ici on estime la variance grâce à la formule de la variance d'une loi de Bernouilli \n",
    "                                  # ceci se justifie par le fait que l'événement (clic ou non) est booléen (1 ou 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = size_sample_AB_test(risk1 = risk1, risk2 = risk2, var = var, mde = mde)\n",
    "sample_size = int(sample_size)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## B/ Une fois les données récupérées on procède au test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On utilise la formule vue plus haut :\n",
    "    $$\\bar{X}^A - \\bar{X}^B\\rightarrow \\mathcal{N}\\Big(0,\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}\\Big)$$\n",
    "    \n",
    "Qui est équivalent à la formule suivante :\n",
    "\n",
    "$$\\frac{\\bar{X}^A - \\bar{X}^B}{\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}}\\rightarrow \\mathcal{N}\\Big(0, 1\\big)$$\n",
    "\n",
    "Notre statistique de test sera donc $t_{AB} = \\frac{\\bar{X}^A - \\bar{X}^B}{\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}} $ que l'on va comparer au seuil fixé pour respecter le risque de première espèce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test_H0(x_A, x_B, risk1, bilateral=False):\n",
    "    \n",
    "    # Calcul de t_AB : différence des moyennes normalisée\n",
    "    diff_mean = (np.mean(x_B) - np.mean(x_A)) # diff entre les moyennes\n",
    "    std_pooled = np.sqrt((np.var(x_A)/len(x_A)) + (np.var(x_A)/len(x_A))) # estimation de l'écart-type joint\n",
    "    stat = diff_mean/std_pooled # différence normalisée\n",
    "    \n",
    "    # Seuil correspondant au risk de première espèce défini\n",
    "    if bilateral :\n",
    "        t = scs.norm(0,1).ppf(1 - risk1/2)\n",
    "    else :\n",
    "        t = scs.norm(0,1).ppf(1 - risk1)\n",
    "\n",
    "    return (stat < t), t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On vérifie sur une simulation qu'avec la taille d'échantillon choisi, le risque de deuxième espèce sera proche de celui ciblé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results_test_simu = []\n",
    "mean_A = p\n",
    "mean_B = p + mde\n",
    "\n",
    "for ii in range(0,10000):\n",
    "    \n",
    "    x_A = np.random.binomial(1, mean_A, size=sample_size)\n",
    "    x_B = np.random.binomial(1, mean_B, size=sample_size)\n",
    "    \n",
    "    # vaut 1 si H_0 est acceptée (à tort ici car mean_A <> mean_B)\n",
    "    results_test_simu.append(test_H0(x_A, x_B, risk1)[0])\n",
    "\n",
    "\"Calcul par simulation du risque de deuxième espèce : {}%\".format(int((np.mean(results_test_simu))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results_test_simu = []\n",
    "mean_A = p\n",
    "mean_B = p\n",
    "\n",
    "for ii in range(0,10000):\n",
    "    \n",
    "    x_A = np.random.binomial(1, mean_A, size=sample_size)\n",
    "    x_B = np.random.binomial(1, mean_B, size=sample_size)\n",
    "    \n",
    "    # vaut 1 si H_0 est accepté (à raison ici car mean_A = mean_B)\n",
    "    results_test_simu.append(test_H0(x_A, x_B, risk1)[0])\n",
    "\n",
    "\"Calcul par simulation de l'erreur de première espèce du test : {}%\".format(int((1 - np.mean(results_test_simu))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## C/ Si on rejette l'hypothèse nulle, on calcule l'intervalle de confiance du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_A = np.random.binomial(1, mean_A, size=sample_size)\n",
    "x_B = np.random.binomial(1, mean_A + mde, size=sample_size)\n",
    "test_H0(x_A, x_B, risk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def confidence_interval_diff(x_A, x_B, sig_level=0.05):\n",
    "    mean_diff = np.mean(x_B) - np.mean(x_A)\n",
    "    var_diff = np.var(x_B)/len(x_B) + np.var(x_A)/len(x_A)\n",
    "    \n",
    "    gap = (scs.norm(0,1).ppf(1 - sig_level/2))*np.sqrt(var_diff)\n",
    "    \n",
    "    min_ = mean_diff - gap\n",
    "    max_ = mean_diff + gap\n",
    "    \n",
    "    return(min_,max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "confidence_interval_diff(x_A, x_B) # x_B - x_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## D/ Si on accepte l'hypothèse nulle, on précise la puissance du test ou le risque de deuxième espèce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On fait l'hypothèse que l'écart vaut le minimum détectable effect. On a alors : \n",
    "\n",
    "$$\\frac{\\bar{X}^A - \\bar{X}^B}{\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}}\\rightarrow \\mathcal{N}\\Big(\\frac{mde}{\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}}, 1\\Big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N_A = 2900\n",
    "N_B = 2900\n",
    "\n",
    "x_A = np.random.binomial(1, p, size=N_A)\n",
    "x_B = np.random.binomial(1, p + mde, size=N_B)\n",
    "\n",
    "var_A = np.var(x_A)\n",
    "var_B = np.var(x_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def power_test(var_A, var_B ,mde ,risk1) :\n",
    "    std_pooled = np.sqrt(var_A/N_A + var_B/N_B)\n",
    "    expectation = mde/std_pooled\n",
    "    t = test_H0(x_A, x_B, risk1)[1]\n",
    "    \n",
    "    return (1 - scs.norm(expectation,1).cdf(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "power_test(var_A,var_B,mde,risk1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Des groupes de taille différentes\n",
    "\n",
    "Si on souhaite des taille d'échantillon différentes on va utiliser $r$ la proportion entre les deux pour calculer la taille d'échantillon :\n",
    "\n",
    "$$N_{A} = \\frac{r+1}{r} \\times \\frac{\\sigma^2\\times(Z_{\\alpha} + Z_{\\beta})^2}{(mde)^2} $$\n",
    "\n",
    "\n",
    "$$N_{B} = r \\times N_{A}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Des effectifs réduits\n",
    "\n",
    "Si on souhaite un test pour des tailles d'échantillon plus petits on utilise une loi de student plutôt qu'une loi normale. On utilise alors la formule suivante\n",
    "\n",
    "$$\\frac{\\bar{X}^A - \\bar{X}^B}{\\sqrt{\\frac{S_A^2}{N_A} + \\frac{S_B^2}{N_B}}} \\rightarrow \\mathcal{student}\\big(N_A + N_B -2 \\big)$$\n",
    "\n",
    "Dans ce cas on fait deux hypothèses suplémentaires : \n",
    "* les variances sont normales ;\n",
    "* les variances sont proches(facteur 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Le problème du _multi-armed bandit_\n",
    "\n",
    "Lorsque le coût d'un A/B testing classic est trop élevé, il devient nécessaire de minimiser le regret, c'est-à-dire l'écart à l'optimal absolu.\n",
    "\n",
    "Une solution est de reformuler le problème d'A/B testing comme un problème de _multi-armed bandit_. On a plusieurs choix possibles (par exemple \"A\", \"B\" et \"C\") rapportant chaucun un _\"revenu\"_ moyen différent mais inconnu a priori. \n",
    "\n",
    "La question est alors de savoir quelle option choisir pour un échantillon de n individus ?\n",
    "\n",
    "La difficulté va être d'arbitrer entre explorer les choix tout en réduisant le regret.\n",
    "\n",
    "Formellement le regret est : $$ r_n = n\\times\\mu^* - \\sum_{k=1}^{n}\\mathbb{E}[\\mu_{I_k}]$$\n",
    "\n",
    "Avec : \n",
    "* n : la taille de l'échantillon\n",
    "* $\\mu^*$ : la moyenne pour le meilleur choix\n",
    "* $I_k$ : le choix pour l'individu k (ici $I_k \\in \\{A,B,C\\}$)\n",
    "* $\\mathbb{E}[\\mu_{I_k}]$ : le revenu espéré pour le choix $I_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Une solution au problème : l'algorithme UCB (upper confidence bound)\n",
    "\n",
    "La stratégie peut être résumée comme suit : on choisit l'option qui rapporte le plus en moyenne avec un bonus d'autant plus grand que l'option a été peu choisie. L'idée est de choisir l'option qui, lorsque l'on est optimiste, a le plus de chance de rapporter (lorsque l'on est optimiste une option peu explorée est supposée rapporter plus). On a alors deux cas de figure :\n",
    "* soit l'option rapporte beaucoup est alors on maintien le regret à un niveau bas\n",
    "* soit l'option rapporte peu et on apprend beaucoup (le résultat est très éloigné de l'attente)\n",
    "\n",
    "Formellement, à chaque étape k (pour chaque individu k) on calcule la valeur de l'UCB pour chacune des options $I\\in \\{A,B,C\\}$ : \n",
    "$$ UCB_I(k) = \\bar{\\mu}^{k-1}_{I} + \\sqrt{\\frac{2ln(k)}{T_I(k-1)}} $$\n",
    "\n",
    "Avec :\n",
    "* $\\bar{\\mu}^{k-1}_{I}$ : la moyenne empirique des revenus générés par l'option I après k-1 essais\n",
    "* $T_I(k-1)$ : le nombre de fois que l'option I a été choisie avec k-1 essais\n",
    "\n",
    "On choisit alors l'option dont l'UCB est la plus élevée : \n",
    "$$ I_k = argmax_{I} UCB_I(k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quand utiliser ce type d'algorithmes ?\n",
    "L'algorithme UCB est réalisé par étape, ce qui nécessite d'attendre le résultat pour un individu avant the faire le choix de l'option pour l'individu suivant. Lorsque le résultat du choix n'est récupérable que longtemps après, il n'est pas envisageable de reformuler le problème comme un problème de multi-armed bandit (par exemple, pour tester les effets à long terme d'un médicament)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Le fait d'utiliser un algorithme de RL n'est _a priori_ pas incompatible avec les étapes classiques de l'A/B testing :__\n",
    "\n",
    "* estimer la taille de l'échantillon nécessaire (bien qu'il est en théorie possible d'appliquer l'algorithme de reinforcement learning sur tous les individus à venir - à long terme c'est, dans les cas simples, la meilleure option qui sera choisie systématiquement)\n",
    "* réaliser un test de significativité des différences (si on souhaite choisir l'une des options de manière définitive)\n",
    "* donner un intervalle de confiance autour des moyennes (cela peut être important pour évaluer le ROI notamment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <h1>Take away</h1> </center>\n",
    "\n",
    "<img src=\"./images/coffee.png\" width=\"200\">\n",
    "\n",
    "\n",
    "__Expresso__ : \n",
    "\n",
    "* Comparer deux moyennes _\"à l'oeil nu\"_ ne suffit pas\n",
    "* Il faut préparer son test en lien avec le métier pour définir les risques acceptables et l'effet minimum détectable recherché\n",
    "* Il faut constituer ses échantillons de manière aléatoire\n",
    "* Si une différence n'est pas significative, cela ne veut pas dire qu'il n'y a pas de différence du tout ! Cela peut venir d'un manque de données et donc de précision\n",
    "* Lorsqu'on accepte l'hypothèse nulle, on indique la puissance du test pour le mde défini\n",
    "* Lorsque l'on rejette l'hypothèse nulle, on analyse un intervalle de confiance plutôt qu'une valeur unique\n",
    "\n",
    "__Sugar Story__ :\n",
    "\n",
    "* Des AB testing sont parfois réalisés _\"à l'oeil nu\"_ (même dans des grands groupes)\n",
    "* Savoir calculer des intervalles de confiance de tête permet parfois d'éviter des boulettes (oups !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Références : \n",
    "* Tests paramétriques de comparaison de 2 moyennes, José LABARERE, Université Joseph Fourier de Grenoble\n",
    "* https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Get more on my github <img src=\"./images/github.png\" width=\"100\">\n",
    "https://github.com/JJublanc/statistics_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to slides AB_testing.ipynb --post serve"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
